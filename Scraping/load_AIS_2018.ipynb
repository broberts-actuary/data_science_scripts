{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-fac54cbad49e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mfileInfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-fac54cbad49e>\u001b[0m in \u001b[0;36mfileInfo\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcsvRef\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mgetCSVHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcsvRef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvRef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "class fileList:\n",
    "    import csv\n",
    "    import os\n",
    "\n",
    "    \n",
    "    def __init__(self, rt, pre):\n",
    "        self.root = rt\n",
    "        self.tablePrefix = pre\n",
    "        self.headerList = []\n",
    "        self.fileList = []\n",
    "\n",
    "        \n",
    "    def collectFileInfo(self,filefunction,limit = None,topDir = os.path.curdir):\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        for root, dirs, files in os.walk(topDir, topdown=True):\n",
    "            #Trim down lists to include only non-skipped directories and only csv files\n",
    "            dirs[:] = [d for d in dirs if \"-skip-\" not in d]\n",
    "            files[:] = [f for f in files if \".csv\" in f]\n",
    "\n",
    "            for file in files:\n",
    "                curCSV = getCSVdetails(file)\n",
    "                addCSVtoList(curCSV[]\n",
    "                ])\n",
    "\n",
    "\n",
    "                counter = counter + 1\n",
    "\n",
    "                if counter > limit:\n",
    "                    break\n",
    "\n",
    "            #for testing, limit number of iterations\n",
    "            if counter > limit:\n",
    "                break\n",
    "\n",
    "        #print(fileList)\n",
    "            \n",
    "    def getCSVdetails(self,file):\n",
    "        csvRef = os.path.abspath(os.path.join(self.root,file))\n",
    "        csvHead = getHeader(csvRef)\n",
    "        csvType = lookupHeader(csvHead)\n",
    "        \n",
    "        return {'path': csvRef , 'fieldFormat': csvType}        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def getHeader(self,csvRef):       \n",
    "        try:\n",
    "            with open(csvRef, newline='') as csvFile:\n",
    "                reader = csv.reader(csvFile)\n",
    "                headerList = next(reader)\n",
    "            csvHead = ','.join(headerList)\n",
    "        except:\n",
    "            csvHead = 'CSV header error'\n",
    "            print('Error retreiving header for ' + csvRef)\n",
    "        csvHead = ''.join(headerStr)\n",
    "        return csvHead    \n",
    "    \n",
    "    def lookUpHeader(self,csvHead):\n",
    "        if csvHead in self.headerList:\n",
    "            headIndex = self.headerList.index(csvHead)\n",
    "            tableName = self.tablePrefix + ('00' + str(headIndex))[-2]\n",
    "        else:\n",
    "            #add csvHead to dic\n",
    "            headList.append(csvHead)\n",
    "            headIndex = headList.index(csvHead)\n",
    "            tableName = tablePrefix + ('00' + str(headIndex))[-2]\n",
    "            #addNewSQLTable(tableName, csvHead)\n",
    "        return tableName\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def addFile(self,file):\n",
    "        csvRef = getDir(self,file)\n",
    "        dbTable = lookUpHeader(self,file)\n",
    "        self.fileList.extend([[csvRef,dbTable,5]])\n",
    "        return\n",
    "    \n",
    "    def getFileList(self):\n",
    "        return self.fileList\n",
    "    \n",
    "    def printHeaderFormatTemplates(self):\n",
    "        return\n",
    "    \n",
    "    def importHeaderFormats(self,formats):\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvToSQL(csvRef,csvHead, dbTable):\n",
    "        cursor = dbConnection.cursor()\n",
    "        csvDockerRef = '/home' + csvRef\n",
    "        sql_code = \"\"\"COPY -dbTable-(-csvHead-) FROM '-csvRef-' DELIMITER ',' CSV HEADER;\"\"\"\n",
    "        sql_code = sql_code.replace('-dbTable-',dbTable).replace('-csvHead-',csvHead).replace('-csvRef-',csvDockerRef)\n",
    "        cursor.execute(sql_code)\n",
    "        updatedRows = cursor.rowcount()\n",
    "        dbConnection.commit()\n",
    "        cursor.close()\n",
    "        print(\"add data\")\n",
    "        return #updatedRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #csvToSQL(csvRef, csvHead, dbTable)\n",
    "        #rowCount = csvToSQL(csvRef, csvHead, dbConnection, dbTable)\n",
    "\n",
    "        #fileList.extend([[csvRef,dbTable,rowCount]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newImport = fileInfo('root path')\n",
    "\n",
    "\n",
    "\n",
    "fileList = [] \n",
    "\n",
    "\n",
    "    print(counter)\n",
    "            \n",
    "            print(csvRef)\n",
    "            csvHead = getCSVHeader(csvRef)\n",
    "            print(csvHead)\n",
    "            dbTable = lookUpHeader(csvHead)\n",
    "            print(dbTable)\n",
    "\n",
    "\n",
    "\n",
    "            counter = counter + 1\n",
    "            #for testing, limit number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "host = '172.18.0.3'\n",
    "db = 'VesselTracking2018'\n",
    "tablePrefix = 'source.ais_2018_'\n",
    "user = 'postgres'\n",
    "password = 'postgres'\n",
    "\n",
    "#dbConnection = psycopg2.connect(host=host, database=db, user=user, password=password)\n",
    "\n",
    "#importAllCSVs(topDir)\n",
    "\n",
    "#dbConnection.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PG implementation\n",
    "import psycopg2\n",
    "\n",
    "def importAllCSVs(topDir = os.path.curdir):\n",
    "\n",
    "    fileList = []\n",
    "    counter = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(topDir, topdown=True):\n",
    "        #Trim down lists to include only non-skipped directories and only csv files\n",
    "        dirs[:] = [d for d in dirs if \"-skip-\" not in d]\n",
    "        files[:] = [f for f in files if \".csv\" in f]\n",
    "\n",
    "        for file in files:\n",
    "            print(counter)\n",
    "            csvRef = os.path.abspath(os.path.join(root,file))\n",
    "            print(csvRef)\n",
    "            csvHead = getCSVHeader(csvRef)\n",
    "            print(csvHead)\n",
    "            dbTable = lookUpHeader(csvHead)\n",
    "            print(dbTable)\n",
    "\n",
    "            csvToSQL(csvRef, csvHead, dbTable)\n",
    "            #rowCount = csvToSQL(csvRef, csvHead, dbConnection, dbTable)\n",
    "\n",
    "            #fileList.extend([[csvRef,dbTable,rowCount]])\n",
    "            fileList.extend([[csvRef,dbTable,5]])\n",
    "\n",
    "            counter = counter + 1\n",
    "            #for testing, limit number of iterations\n",
    "            if counter >10:\n",
    "                break\n",
    "\n",
    "        #for testing, limit number of iterations\n",
    "        if counter >10:\n",
    "            break\n",
    "\n",
    "    #print(fileList)\n",
    "\n",
    "\n",
    "host = '172.18.0.3'\n",
    "db = 'VesselTracking2018'\n",
    "tablePrefix = 'source.ais_2018_'\n",
    "user = 'postgres'\n",
    "password = 'postgres'\n",
    "\n",
    "dbConnection = psycopg2.connect(host=host, database=db, user=user, password=password)\n",
    "\n",
    "importAllCSVs()\n",
    "\n",
    "dbConnection.close()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#run info\n",
    "topDir = os.path.abspath('D:\\AIS_2018\\Commercial Data\\WorkOrder6931168-Ippolito#8of12')\n",
    "\n",
    "#DB info\n",
    "server = 'KNXDEVSQL01'\n",
    "database = 'VESSEL_TRACKING_02'\n",
    "username = 'DAgeneral'\n",
    "password = 'ABS123!'\n",
    "\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "#cursor = cnxn.cursor()\n",
    "\n",
    "print(topDir)\n",
    "\n",
    "importAllCSVs(topDir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNewSQLTable(tableName, csvHead):\n",
    "        cursor = dbConnection.cursor()\n",
    "        newFields = csvHead.replace(',',' text,')\n",
    "        newFields = newFields + ' text'\n",
    "        sql_code = \"\"\"CREATE TABLE -tableName-(-newFields-);\"\"\"\n",
    "        sql_code = sql_code.replace('-tableName-',tableName).replace('-newFields-',newFields)\n",
    "        cursor.execute(sql_code)\n",
    "        #updatedRows = cursor.rowcount()\n",
    "        dbConnection.commit()\n",
    "        cursor.close()\n",
    "        print('added table: ' + tableName)\n",
    "        return #updatedRows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
